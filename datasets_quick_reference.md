# Quick Reference: Reasoning Datasets

å¿«é€Ÿå‚è€ƒè¡¨æ ¼ - æ‰€æœ‰æ¨ç†æ•°æ®é›†ä¸€è§ˆ

## æ•°å­¦æ¨ç†æ•°æ®é›† (Mathematical Reasoning)

| æ•°æ®é›†åç§° | æ•°æ®é‡ | éš¾åº¦ | HuggingFace ID | è¯­è¨€ | ç‰¹ç‚¹ |
|-----------|--------|------|----------------|------|------|
| GSM8K | 8.5K | å°å­¦ | `gsm8k` | EN | è¯¦ç»†è§£é¢˜æ­¥éª¤ |
| MATH | 12.5K | ç«èµ›çº§ | `competition_math` | EN | LaTeXæ ¼å¼ï¼Œå¤šå­¦ç§‘ |
| AQuA-RAT | 100K | ä»£æ•° | `aqua_rat` | EN | å¤šé€‰é¢˜+æ¨ç† |
| MathQA | 37K | ä¸­ç­‰ | `math_qa` | EN | æ“ä½œç¨‹åº |
| MetaMathQA | 395K | å„çº§ | `meta-math/MetaMathQA` | EN | æ•°æ®å¢å¼º+CoT |
| CMATH | 1.7ä¸‡ | å°å­¦ | - | CN | ä¸­æ–‡æ•°å­¦é¢˜ |

## é€»è¾‘æ¨ç†æ•°æ®é›† (Logical Reasoning)

| æ•°æ®é›†åç§° | æ•°æ®é‡ | ç±»å‹ | HuggingFace ID | è¯­è¨€ | ç‰¹ç‚¹ |
|-----------|--------|------|----------------|------|------|
| LogiQA | 8.7K | é€»è¾‘æ¨ç† | `logiqa` | CN/EN | å…¬åŠ¡å‘˜è€ƒè¯• |
| ReClor | 6K | é˜…è¯»ç†è§£ | - | EN | æ·±åº¦æ¨ç† |
| ProofWriter | 600K | å½¢å¼é€»è¾‘ | `allenai/proofwriter` | EN | å®Œæ•´æ¨ç†é“¾ |
| FOLIO | 1.4K | ä¸€é˜¶é€»è¾‘ | - | EN | ä¸“å®¶æ ‡æ³¨ |
| AR-LSAT | ä¸­é‡ | åˆ†ææ¨ç† | - | EN | LSATè€ƒé¢˜ |

## å¸¸è¯†æ¨ç†æ•°æ®é›† (Commonsense Reasoning)

| æ•°æ®é›†åç§° | æ•°æ®é‡ | ç±»å‹ | HuggingFace ID | è¯­è¨€ | ç‰¹ç‚¹ |
|-----------|--------|------|----------------|------|------|
| CommonsenseQA | 12K | å¸¸è¯†é—®ç­” | `commonsense_qa` | EN | å¤šé€‰é¢˜ |
| StrategyQA | 2.7K | éšå¼æ¨ç† | `wics/strategy-qa` | EN | æ˜¯éé¢˜ |
| PIQA | 21K | ç‰©ç†å¸¸è¯† | `piqa` | EN | æ—¥å¸¸äº¤äº’ |
| COPA | 1K | å› æœæ¨ç† | `super_glue` (copa) | EN | å› æœå…³ç³» |
| CSQA 2.0 | - | å¸¸è¯†é—®ç­” | `tau/commonsense_qa_2.0` | EN | æ›´å…·æŒ‘æˆ˜ |

## ç»¼åˆæ¨ç†æ•°æ®é›† (Comprehensive Reasoning)

| æ•°æ®é›†åç§° | æ•°æ®é‡ | é¢†åŸŸ | HuggingFace ID | è¯­è¨€ | ç‰¹ç‚¹ |
|-----------|--------|------|----------------|------|------|
| MMLU | 15.9K | 57å­¦ç§‘ | `cais/mmlu` | EN | å¤šä»»åŠ¡ |
| BIG-Bench Hard | 23ä»»åŠ¡ | ç»¼åˆ | `lukaemon/bbh` | EN | æœ€éš¾ä»»åŠ¡ |
| ARC-Easy | 2.3K | ç§‘å­¦ | `ai2_arc` (ARC-Easy) | EN | å®¹æ˜“ |
| ARC-Challenge | 1.2K | ç§‘å­¦ | `ai2_arc` (ARC-Challenge) | EN | å›°éš¾ |
| OpenBookQA | 6K | å¼€å· | `openbookqa` | EN | çŸ¥è¯†+æ¨ç† |
| HellaSwag | 70K | æƒ…å¢ƒ | `hellaswag` | EN | å¸¸è¯†æ¨ç† |
| C-Eval | 13.9K | 52å­¦ç§‘ | - | CN | ä¸­æ–‡ç»¼åˆ |
| CMMLU | å¤šä»»åŠ¡ | ç»¼åˆ | `haonan-li/cmmlu` | CN | ä¸­æ–‡MMLU |

## ä»£ç æ¨ç†æ•°æ®é›† (Code Reasoning)

| æ•°æ®é›†åç§° | æ•°æ®é‡ | éš¾åº¦ | HuggingFace ID | è¯­è¨€ | ç‰¹ç‚¹ |
|-----------|--------|------|----------------|------|------|
| HumanEval | 164 | ä¸­ç­‰ | `openai_humaneval` | Python | OpenAIåŸºå‡† |
| MBPP | 974 | åŸºç¡€ | `mbpp` | Python | å¸¦æµ‹è¯•ç”¨ä¾‹ |
| APPS | 10K | å„çº§ | `codeparrot/apps` | Python | ç«èµ›çº§ |
| CodeContests | 13K | é«˜éš¾åº¦ | `deepmind/code_contests` | å¤šè¯­è¨€ | DeepMind |

## æ€ç»´é“¾æ•°æ®é›† (Chain-of-Thought)

| æ•°æ®é›†åç§° | æ•°æ®é‡ | ç±»å‹ | HuggingFace ID | è¯­è¨€ | ç‰¹ç‚¹ |
|-----------|--------|------|----------------|------|------|
| MetaMathQA | 395K | æ•°å­¦ | `meta-math/MetaMathQA` | EN | è¯¦ç»†æ­¥éª¤ |
| FLAN Collection | å¤§è§„æ¨¡ | å¤šä»»åŠ¡ | `conceptofmind/FLAN_2022` | EN | æŒ‡ä»¤å¾®è°ƒ |
| WizardLM | 196K | ç»¼åˆ | `WizardLM/WizardLM_evol_instruct_V2_196k` | EN | è¿›åŒ–æŒ‡ä»¤ |

## å¿«é€ŸåŠ è½½ä»£ç 

### Pythonä»£ç ç¤ºä¾‹

```python
from datasets import load_dataset

# æ•°å­¦æ¨ç†
gsm8k = load_dataset("gsm8k", "main")
math = load_dataset("competition_math")
mathqa = load_dataset("math_qa")

# é€»è¾‘æ¨ç†
logiqa = load_dataset("logiqa")
proofwriter = load_dataset("allenai/proofwriter")

# å¸¸è¯†æ¨ç†
commonsenseqa = load_dataset("commonsense_qa")
piqa = load_dataset("piqa")
copa = load_dataset("super_glue", "copa")

# ç»¼åˆæ¨ç†
mmlu = load_dataset("cais/mmlu", "all")
arc_easy = load_dataset("ai2_arc", "ARC-Easy")
arc_challenge = load_dataset("ai2_arc", "ARC-Challenge")
openbookqa = load_dataset("openbookqa", "main")
hellaswag = load_dataset("hellaswag")

# ä»£ç æ¨ç†
humaneval = load_dataset("openai_humaneval")
mbpp = load_dataset("mbpp")
apps = load_dataset("codeparrot/apps")

# æ€ç»´é“¾
metamath = load_dataset("meta-math/MetaMathQA")
```

## æ•°æ®é›†é€‰æ‹©å»ºè®®

### æŒ‰è®­ç»ƒç›®æ ‡é€‰æ‹©

| è®­ç»ƒç›®æ ‡ | æ¨èæ•°æ®é›†ç»„åˆ |
|---------|---------------|
| æ•°å­¦èƒ½åŠ› | GSM8K + MATH + MetaMathQA |
| é€»è¾‘æ¨ç† | LogiQA + ProofWriter + ReClor |
| å¸¸è¯†ç†è§£ | CommonsenseQA + PIQA + StrategyQA |
| é€šç”¨æ¨ç† | MMLU + ARC + OpenBookQA + BIG-Bench |
| ä»£ç ç”Ÿæˆ | HumanEval + MBPP + APPS |
| ä¸­æ–‡æ¨ç† | CMATH + C-Eval + CMMLU + LogiQA |

### æŒ‰éš¾åº¦é€’è¿›

1. **å…¥é—¨çº§**: PIQA, COPA, ARC-Easy, MBPP
2. **ä¸­çº§**: GSM8K, CommonsenseQA, HumanEval, ARC-Challenge
3. **é«˜çº§**: MATH, ReClor, OpenBookQA, APPS
4. **ä¸“å®¶çº§**: BIG-Bench Hard, CodeContests, Competition Math

### æŒ‰æ•°æ®é‡

| è§„æ¨¡ | æ•°æ®é›†ç¤ºä¾‹ |
|-----|-----------|
| å°å‹ (< 2K) | COPA, FOLIO, StrategyQA |
| ä¸­å‹ (2K-10K) | GSM8K, LogiQA, CommonsenseQA, ARC |
| å¤§å‹ (10K-50K) | MATH, PIQA, MathQA |
| è¶…å¤§å‹ (> 50K) | AQuA-RAT, HellaSwag, MetaMathQA |

## æ•°æ®é›†è´¨é‡è¯„åˆ†

| æ•°æ®é›† | è´¨é‡ | æ ‡æ³¨ | æ¨ç†æ·±åº¦ | æ¨èåº¦ |
|--------|------|------|---------|--------|
| GSM8K | â­â­â­â­â­ | äººå·¥ | å¤šæ­¥ | â­â­â­â­â­ |
| MATH | â­â­â­â­â­ | äººå·¥ | æ·±åº¦ | â­â­â­â­â­ |
| MetaMathQA | â­â­â­â­ | åˆæˆ | å¤šæ­¥ | â­â­â­â­ |
| CommonsenseQA | â­â­â­â­â­ | äººå·¥ | ä¸­åº¦ | â­â­â­â­â­ |
| LogiQA | â­â­â­â­â­ | äººå·¥ | æ·±åº¦ | â­â­â­â­â­ |
| MMLU | â­â­â­â­â­ | äººå·¥ | å„çº§ | â­â­â­â­â­ |
| HumanEval | â­â­â­â­â­ | äººå·¥ | ä¸­åº¦ | â­â­â­â­â­ |
| ProofWriter | â­â­â­â­ | åˆæˆ | æ·±åº¦ | â­â­â­â­ |

## æ··åˆæ•°æ®é›†é…æ–¹

### é€šç”¨æ¨ç†æ¨¡å‹
```
30% æ•°å­¦æ¨ç† (GSM8K + MATH)
25% å¸¸è¯†æ¨ç† (CommonsenseQA + PIQA)
20% é€»è¾‘æ¨ç† (LogiQA + ProofWriter)
15% ç§‘å­¦æ¨ç† (ARC + OpenBookQA)
10% ä»£ç æ¨ç† (HumanEval + MBPP)
```

### æ•°å­¦ä¸“å®¶æ¨¡å‹
```
40% GSM8K
30% MATH
20% MetaMathQA
10% MathQA
```

### ä»£ç ä¸“å®¶æ¨¡å‹
```
40% MBPP
30% HumanEval
20% APPS
10% CodeContests
```

### ä¸­æ–‡æ¨ç†æ¨¡å‹
```
30% CMATH
30% C-Eval
20% CMMLU
20% LogiQA (ä¸­æ–‡)
```

## è¯„ä¼°åŸºå‡†

| åŸºå‡†æµ‹è¯• | è¯„ä¼°å†…å®¹ | éš¾åº¦ | ä½¿ç”¨åœºæ™¯ |
|---------|---------|------|---------|
| GSM8K | æ•°å­¦æ¨ç† | ä¸­ | åŸºç¡€æ•°å­¦èƒ½åŠ› |
| MATH | é«˜çº§æ•°å­¦ | é«˜ | ç«èµ›çº§æ•°å­¦ |
| MMLU | ç»¼åˆçŸ¥è¯† | ä¸­-é«˜ | é€šç”¨èƒ½åŠ› |
| BIG-Bench Hard | ç»¼åˆæ¨ç† | æé«˜ | å‰æ²¿èƒ½åŠ› |
| HumanEval | ä»£ç ç”Ÿæˆ | ä¸­ | ç¼–ç¨‹èƒ½åŠ› |
| C-Eval | ä¸­æ–‡çŸ¥è¯† | ä¸­-é«˜ | ä¸­æ–‡èƒ½åŠ› |

## æœ€ä½³å®è·µæ€»ç»“

âœ… **æ¨èåšæ³•**
- æ··åˆå¤šç§æ¨ç†ç±»å‹
- ä½¿ç”¨åŒ…å«æ¨ç†æ­¥éª¤çš„æ•°æ®é›†
- ä»ç®€å•åˆ°å›°éš¾é€’è¿›è®­ç»ƒ
- å®šæœŸåœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
- å¹³è¡¡ä¸åŒæ•°æ®é›†çš„æ ·æœ¬é‡

âŒ **é¿å…åšæ³•**
- åªä½¿ç”¨å•ä¸€ç±»å‹æ•°æ®é›†
- å¿½è§†æ•°æ®è´¨é‡
- æ•°æ®åˆ†å¸ƒä¸¥é‡å¤±è¡¡
- è¿‡åº¦ä¾èµ–åˆæˆæ•°æ®
- ç¼ºä¹è¯„ä¼°éªŒè¯

## èµ„æºé“¾æ¥

- ğŸ“š è¯¦ç»†æŒ‡å—: [reasoning_datasets_guide.md](reasoning_datasets_guide.md)
- ğŸ’» å®æˆ˜æ•™ç¨‹: [reasoning_datasets_tutorial.ipynb](reasoning_datasets_tutorial.ipynb)
- ğŸ  ä¸»é¡µ: [README.md](README.md)

---

**æ›´æ–°æ—¶é—´**: 2025-10-15
